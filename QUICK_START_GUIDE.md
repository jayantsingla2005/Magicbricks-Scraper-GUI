# ðŸš€ MagicBricks Scraper - Quick Start Guide

## ðŸ“ **CLEAN PROJECT STRUCTURE**

```
MagicBricks/
â”œâ”€â”€ ðŸ“„ integrated_magicbricks_scraper.py    # Main scraper engine
â”œâ”€â”€ ðŸ–¥ï¸ magicbricks_gui.py                   # GUI interface
â”œâ”€â”€ âš™ï¸ user_mode_options.py                 # Scraping modes
â”œâ”€â”€ ðŸ”„ incremental_scraping_system.py       # Incremental logic
â”œâ”€â”€ ðŸ“… date_parsing_system.py               # Date processing
â”œâ”€â”€ ðŸ›‘ smart_stopping_logic.py              # Smart stopping
â”œâ”€â”€ ðŸ”— url_tracking_system.py               # URL management
â”œâ”€â”€ âŒ error_handling_system.py             # Error handling
â”œâ”€â”€ ðŸ—ƒï¸ incremental_database_schema.py       # Database setup
â”œâ”€â”€ ðŸ“Š enhanced_data_schema.py              # Data schema
â”œâ”€â”€ ðŸ“‹ requirements.txt                     # Dependencies
â”œâ”€â”€ ðŸ“– README.md                           # Main documentation
â”œâ”€â”€ ðŸ‘¤ USER_MANUAL.md                      # User guide
â”œâ”€â”€ ðŸ—„ï¸ magicbricks_enhanced.db             # Database file
â”œâ”€â”€ ðŸ“ integrated_scraper.log              # Current log
â”œâ”€â”€ ðŸ“ config/                             # Configuration files
â”œâ”€â”€ ðŸ“ data/                               # Data files
â””â”€â”€ ðŸ“ archive/                            # Archived files
```

## ðŸŽ¯ **HOW TO RUN THE SCRAPER**

### **Method 1: GUI Interface (Recommended)**

1. **Open Command Prompt/Terminal**
   ```bash
   cd "D:/real estate/Scrapers/Magicbricks"
   ```

2. **Launch GUI**
   ```bash
   python magicbricks_gui.py
   ```

3. **Configure Settings**
   - Select city from dropdown
   - Choose scraping mode (Incremental/Full/Conservative)
   - Set maximum pages
   - Configure advanced settings if needed

4. **Start Scraping**
   - Click "Start Scraping" button
   - Monitor progress in real-time
   - Wait for completion

### **Method 2: Command Line**

```python
from integrated_magicbricks_scraper import IntegratedMagicBricksScraper
from user_mode_options import ScrapingMode

# Create scraper instance
scraper = IntegratedMagicBricksScraper()

# Run scraping
result = scraper.scrape_properties_with_incremental(
    city='mumbai',
    mode=ScrapingMode.INCREMENTAL,
    max_pages=5,
    export_formats=['csv', 'json', 'excel']
)
```

## ðŸ“Š **FINDING YOUR OUTPUT FILES**

### **File Naming Convention**
```
magicbricks_{mode}_scrape_{timestamp}.{format}
```

**Examples:**
- `magicbricks_full_scrape_20250811_104531.csv`
- `magicbricks_full_scrape_20250811_104531.json`
- `magicbricks_full_scrape_20250811_104531.xlsx`

### **How to Identify Latest Files**

1. **By Timestamp in Filename**
   - Format: `YYYYMMDD_HHMMSS`
   - Latest = Highest timestamp
   - Example: `20250811_104531` = Aug 11, 2025, 10:45:31

2. **By File Creation Date**
   - Right-click file â†’ Properties â†’ Date Created
   - Sort by "Date Modified" in File Explorer

3. **In GUI**
   - Success message shows exact filename
   - Files are created in main project directory

### **Output File Locations**
- **CSV Files**: Main directory (`magicbricks_*.csv`)
- **JSON Files**: Main directory (`magicbricks_*.json`)
- **Excel Files**: Main directory (`magicbricks_*.xlsx`)
- **Database**: `magicbricks_enhanced.db`
- **Logs**: `integrated_scraper.log`

## ðŸ”§ **ADVANCED FEATURES**

### **Export Formats**
- âœ… **CSV** (Mandatory): Standard spreadsheet format
- âœ… **Database** (Mandatory): SQLite database
- ðŸ“„ **JSON** (Optional): Structured data format
- ðŸ“Š **Excel** (Optional): Multi-sheet workbook with summary

### **Filtering Options**
- ðŸ’° **Price Range**: Filter by price (in Lakhs)
- ðŸ“ **Area Range**: Filter by area (Sq.Ft)
- ðŸ  **BHK Types**: 1, 2, 3, 4, 4+ BHK
- ðŸš« **Exclude Keywords**: Filter out unwanted properties

### **Performance Settings**
- â±ï¸ **Custom Delays**: Adjust scraping speed
- ðŸ”„ **Batch Processing**: Configure batch sizes
- ðŸ’¾ **Memory Optimization**: Enable for large datasets
- ðŸ” **Retry Logic**: Configure retry attempts

## ðŸ“ˆ **UNDERSTANDING OUTPUT DATA**

### **CSV/Excel Columns**
- `title`: Property title
- `price`: Property price
- `area`: Property area
- `property_url`: Direct link to property
- `locality`: Location area
- `society`: Building/society name
- `property_type`: Apartment/House/Plot
- `bathrooms`: Number of bathrooms
- `balcony`: Number of balconies
- `furnishing`: Furnished/Semi/Unfurnished
- `floor_details`: Floor information
- `facing`: Property facing direction
- `parking`: Parking availability
- `ownership`: Ownership type
- `posting_date_text`: When posted
- `data_quality_score`: Quality score (0-100%)

### **JSON Structure**
```json
{
  "metadata": {
    "scrape_timestamp": "2025-08-11T10:45:31",
    "total_properties": 150,
    "session_stats": {...}
  },
  "properties": [...]
}
```

### **Excel Sheets**
1. **Properties**: All property data
2. **Summary**: Scraping statistics
3. **City_Stats**: City-specific metrics

## ðŸš¨ **TROUBLESHOOTING**

### **Common Issues**
1. **"No module named..." Error**
   ```bash
   pip install -r requirements.txt
   ```

2. **GUI Won't Start**
   - Check Python version (3.8+)
   - Install tkinter: `pip install tk`

3. **No Properties Found**
   - Check internet connection
   - Try different city
   - Disable filtering

4. **Slow Performance**
   - Reduce max pages
   - Disable individual page scraping
   - Increase delays in advanced settings

### **Getting Help**
- Check `integrated_scraper.log` for errors
- Review `USER_MANUAL.md` for detailed instructions
- Ensure all dependencies are installed

## ðŸŽ‰ **SUCCESS INDICATORS**

âœ… **Successful Run:**
- GUI shows "Scraping completed successfully"
- Output files created with timestamp
- Log shows no critical errors
- Properties count > 0

âœ… **Quality Data:**
- Data quality score > 80%
- Most essential fields filled
- Valid URLs and prices
- Recent posting dates

---

**ðŸš€ Ready to scrape! Start with the GUI for the best experience.**
